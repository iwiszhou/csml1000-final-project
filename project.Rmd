---
title: "Clustering CDC Data - Nutrition, Physical Activity, & Obesity using Unsupervised and Supervised Learning"
output:
  html_document: default
date:  2019-11-09
bibliography: reference.bib
---

# CSML1000 Project #2, by Group 8
Tamer Hanna <tamerh@my.yorku.ca>
Pete Gray <ptgray@my.yorku.ca>
Xiaohai Lu <yu271637@my.yorku.ca>
Haofeng Zhou <zhf85@my.yorku.ca>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Problem Statement
Obesity is a big problem in North American society, and contributes to increased rates of diabetes, heart disease, stroke, depression, suicide, disability, death, and many other serious problems that I'll look up later.

Using this dataset, we can identify groups at highest risk based on age, gender, race, education, income, etc. Using supervised and unsupervised learning, we can look for unexpected combinations of features that lead to an increased rate of obesity. Using decision trees, we can divine the most critical factors correlated with high rates of obesity. We can do this in general, or within those clusters.

This dataset includes data on adult's diet, physical activity, and weight status from Behavioral Risk Factor Surveillance System. This data is used for DNPAO's Data, Trends, and Maps database, which provides national and state specific data on obesity, nutrition, physical activity, and breastfeeding.  The dataset provider is particularly curious on whether socioeconomic status has an impact on obesity.  In her analysis, she compares the obesity rate in each state, and then perform a linear regression on the obesity rate for each educational status and the income bracket. [@Suzanne] 


## Business Objectives

For any given sample, we can determine the impact of changing different factors on a given group's predicted obesity rate.


## Approach


### **Supervised Learning - build a regression/random forse model**


  1.  **Import the source file** - Nutrition__Physical_Activity__and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System.csv:
```{r importDataFile, echo=FALSE, include=FALSE}
library(tidyverse)
library(dplyr)
library(modelr)


df <- read_csv("Nutrition__Physical_Activity__and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System.csv")
df %>% 
  print(n = 10, width = Inf)
problems(df)

comma <- function(x)  format(x, digits = 2, big.mark = ",")

```
     The source file has `r comma(nrow(df))` rows and `r comma(ncol(df))` columns
### Describe Data

    *  *The data describe 9 different questions and each one has a corresponding precentage which is Data_Value column*

      + 1. Percent of adults aged 18 years and older who have an overweight classification

      + 2. Percent of adults aged 18 years and older who have obesity

      + 3. Percent of adults who achieve at least 150 minutes a week of moderate-intensity aerobic physical activity or 75 minutes a week of vigorous-intensity aerobic activity
      + 4. Percent of adults who achieve at least 150 minutes a week of moderate-intensity aerobic physical activity or 75 minutes a week of vigorous-intensity aerobic physical
      + 5. Percent of adults who achieve at least 300 minutes a week of moderate-intensity aerobic physical activity or 150 minutes a
week of vigorous-intensity aerobic activity
      + 6. Percent of adults who engage in muscle-strengthening activities on 2 or more days a week

      + 7. Percent of adults who engage in no leisure-time physical activity

      + 8. Percent of adults who report consuming fruit less than one time daily

      + 9. Percent of adults who report consuming vegetables less than one time daily

    * *For each of there questions, there are 6 different categories*

      1. Age (years)
      2. Education
      3. Gender
      4. Income
      5. Race/Ethnicity
      6. Total

    * *For each of there categories, which has different values*

      1. *Age (years)* 
        * 18 - 24
        * 25 - 34
        * 35 - 44
        * 45 - 54
        * 55 - 64
        * 65 or older
      2. *Education*       
        * Less than high school
        * High school graduate
        * Some college or technical school
        * College graduate
      3. *Gender* 
        * Male
        * Female
      4. *Income* 
        * Less than $15,000
        * $15,000 - $24,999
        * $25,000 - $34,999
        * $35,000 - $49,999
        * $50,000 - $74,999
        * $75,000 or greater
        * Data not reported
      5. *Race/Ethnicity* 
        * 2 or more races
        * American Indian/Alaska Native
        * Asian
        * Hawaiian/Pacific Islander
        * Hispanic
        * Non-Hispanic Black
        * Non-Hispanic White
        * Other
      6. *Total* 
        * Total

     
  2. **Clean dataset** 
      * **Column Correlation:**
         + LocationAbbr and LocationDesc:
```{r LocationCorr, echo=FALSE}
      dplyr::select(df, LocationAbbr, LocationDesc) %>% count(LocationAbbr, LocationDesc) %>% 
         ggplot() +
          geom_tile( mapping = aes(x=LocationAbbr, y=LocationDesc, fill = n))
```
         + Column Datasource 
```{r DatasourceCol, echo=FALSE}
        ggplot(data=df, mapping = aes(x=Datasource)) + 
            stat_count()
```
         + Class and Topic columns are correlated:
```{r classTopicCorr, echo=FALSE}
      ggplot(data=df, mapping = aes(x=Class, y=Topic)) +
        geom_count()
```
         + Data_Value is the mean of Low_Confidence_Limit and High_Confidence_Limit
```{r DataValueRel, echo=FALSE, warning=FALSE}
  temp_df <- df %>% dplyr::select(Data_Value, Low_Confidence_Limit, High_Confidence_Limit) %>% mutate(row = row_number(), mean_value=(Low_Confidence_Limit +  High_Confidence_Limit)/2 ) 
  temp_df %>% ggplot(mapping=aes(x=Data_Value, y=mean_value)) + 
    geom_boxplot(mapping=aes(group=cut_number(Data_Value, 10)), na.rm = TRUE)

```
         
       
      * **Clean the columns:**
```{r dataStructure, echo=FALSE, results='asis' }
  library(knitr)
  dd <- tibble(
    colName = colnames(df),
    action = c("change to int",
               "remove, corelate with YearStart",
               "pass",
               "remove, correlate with LocationAbbr",
               "remove, may not relate to the problem",
               "remove, correlate with TopicID",
               "remove, because corelate to Class",
               "remove, correlate with QuestionID",
               "remove, contain only NA",
               "remove, contains only value 'Value'",
               "remove 'NA' observations",
               "remove, corelate to Data_Value",
               "remove, correlate to Data_Value_Footnote",
               "remove, contain only NA after removing Data_Value NA obs",
               "remove, Data_Value = mean(Low_confidence_Limit, High_Confidence_Limit)",
               "remove, Data_Value = mean(Low_confidence_Limit, High_Confidence_Limit)",
               "pass",
               "update NA -> 'Unknown'",
               "update colname -> Age, update NA-> 'Unknown'",
               "update NA -> 'Unknown",
               "update NA -> 'Unknown",
               "update NA -> 'Unknown'",
               "update colname -> 'Race' and update NA -> 'Unknown'",
               "remove, correlate to LocationAbbr",
               "remove, correlate with col: TopicID",
               "pass",
               "pass",
               "remove, contain only one value 'VALUE'",
               "remove, corelated with column GeoLocation",
               "remove, corelation with StratificationCategoryId1",
               "remove, corelation with Income, Race/Ethnicity, Gender, Education, Age, Total, sub catigory under spread StratificationCategoryId1",
               "remove, gathered columns from OVR,GEN,EDU,AGEYR,INC,RACE",
               "remove, combined col: StratificationCategoryId1 + Stratification1"
    )
  )
  kable(dd, caption="column list")
```
```{r tidyColumns, echo=FALSE}
    replaceNA <- function(df, colName, value='Unknown') {
      df[[colName]] <- ifelse( is.na(df[[colName]]), value, df[[colName]])
      return(df)
    }

    #replaceNA(df=df, colName = "Data_Value_Footnote", "" )

    clean_df <- df %>%
      dplyr::select( -YearEnd, -LocationDesc, -Datasource, -Class, -Topic, -Question, -Data_Value_Unit, -Data_Value_Type, -Data_Value_Alt,
              -Data_Value_Footnote_Symbol, -Data_Value_Footnote, -GeoLocation, -ClassID, -DataValueTypeID, -LocationID, 
              -StratificationCategory1, -Stratification1, -StratificationCategoryId1, -StratificationID1, 
              -High_Confidence_Limit, -Low_Confidence_Limit ) %>%
      rename( Age = `Age(years)`,  Race = `Race/Ethnicity` )
    
    clean_df <- clean_df %>% replaceNA(. , colName = "Total") %>% replaceNA(. , colName = "Age") %>%  replaceNA(. , colName = "Education") %>%
                replaceNA(. , colName = "Gender") %>% replaceNA(. , colName = "Income") %>% replaceNA(. , colName = "Race") %>%
                filter( !is.na(Data_Value) )
    
    clean_df <- clean_df %>% mutate( YearStart = as.integer(YearStart) )
    
```
  3.  **Visulization - Building Models**
```{r ModelBuildingFunction, echo = FALSE}
  # *******************************************************
  # input:
  #     dataframe is clean_df, dependant variable is Data_Value
  # output:
  #     return: n/a
  # purpose:
  #     plot relationship between dependant and independant variables

  #     generate model dependant ~ independant variables
  #     plot model generated
  #     generate model residual
  #     plot model residual
  exploreFeature <- function(feature, data = clean_df) {
     arg <- match.call()
     tempDF <- data %>% filter(eval(arg$feature) != "Unknown")
     ggplot( tempDF, aes(x = eval(arg$feature), y = Data_Value )) + geom_boxplot()
  }
  buildingModel <- function(feature, data = clean_df) {
     arg <- match.call()
     tempDF <- data %>% filter(eval(arg$feature) != "Unknown")
     
     mod <- lm( Data_Value ~ eval(arg$feature), data = tempDF)
     return(mod)
  }
     #tempDF <- tempDF %>% data_grid( eval(arg$feature ))
  exploreModel <- function(mod, feature, data = clean_df){
     arg <- match.call()
     tempDF <- data %>% filter(eval(arg$feature) != "Unknown")
     tempDF <- tempDF %>% add_predictions(eval(arg$mod))
    
     ggplot( data = tempDF, aes(x=eval(arg$feature))) + 
          geom_point( aes(y = Data_Value )) + 
          geom_point( mapping = aes(y = pred), color = "red", size = 2, fill = "red")
  }
  exploreResidual <- function(feature, data = clean_df){
     arg <- match.call()
     tempDF <- data %>% filter(eval(arg$feature) != "Unknown")
     tempDF <- tempDF %>%
          add_residuals(mod, var = "resid")
     ggplot( data = tempDF, aes(x=eval(arg$feature), y = resid )) + geom_boxplot()
     
  }
  
```
         + **apply for single feature:**
```{r explore features, echo = TRUE}
    exploreFeature(Age )
    mod <- buildingModel(Age)
    exploreModel(mod = mod, Age)
    exploreResidual(Age)
    exploreFeature(YearStart )
    mod <- buildingModel(YearStart)
    exploreModel(mod = mod, YearStart)
    exploreResidual(YearStart)
    exploreFeature(LocationAbbr )
    mod <- buildingModel(LocationAbbr)
    exploreModel(mod = mod, LocationAbbr)
    exploreResidual(LocationAbbr)
    
    exploreFeature( Sample_Size )
    mod <- buildingModel(Sample_Size)
    exploreModel(mod = mod, Sample_Size)
    exploreResidual(Sample_Size)
    

    exploreFeature(Education )
    mod <- buildingModel(Education)
    exploreModel(mod = mod, Education)
    exploreResidual(Education )
    
    exploreFeature(Gender )
    mod <- buildingModel(Gender)
    exploreModel(mod = mod, Gender)
    exploreResidual(Gender)
    
    exploreFeature( Income )
    mod <- buildingModel(Income )
    exploreModel(mod = mod, Income)
    exploreResidual(Income )
    
    exploreFeature( Race )
    mod <- buildingModel(Race)
    exploreModel(mod = mod, Race)
    exploreResidual(Race)
    
    exploreFeature( TopicID)
    mod <- buildingModel(TopicID)
    exploreModel(mod = mod, TopicID)
    exploreResidual(TopicID)
    
    exploreFeature( QuestionID )
    mod <- buildingModel(QuestionID)
    exploreModel(mod = mod, QuestionID)
    exploreResidual(QuestionID)
    
```
  
  
  
         + **Apply for two features**
```{r ModelBuildingFunctionForTwoFeatures, echo = FALSE}
  # *******************************************************
  # input:
  #     dataframe is clean_df, dependant variable is Data_Value
  # output:
  #     return: n/a
  # purpose:
  #     plot relationship between dependant and independant variables

  #     generate model dependant ~ independant variables
  #     plot model generated
  #     generate model residual
  #     plot model residual
  exploreTwoFeatures <- function(feature1, feature2, data = clean_df) {
     arg <- match.call()
     #tempDF <- data %>% filter(eval(arg$feature1) != "Unknown" , eval(arg$feature2) != "Unknown")
     tempDF <- data
     mod1 <- lm( Data_Value ~ eval(arg$feature1) + eval(arg$feature2), data = tempDF)
     mod2 <- lm( Data_Value ~ eval(arg$feature1) * eval(arg$feature2), data = tempDF)
     
     tempDF <- tempDF %>% add_predictions(mod1, var = "pred_ind")
     tempDF <- tempDF %>% add_predictions(mod2, var = "pred_interact")
     
     tempDF <- tempDF %>%
          gather_residuals(mod1, mod2)
     
     ggplot( data = tempDF, aes(x=eval(arg$feature1), y = resid, color = eval(arg$feature2) )) + geom_boxplot() + facet_wrap( ~model )
     
  }
exploreTwoFeatures(feature1 = Race, feature2 = QuestionID)
```
 

         + **generate models**

```{r generateModel, echo = FALSE}
  set.seed(123)
  trainSize <- nrow( clean_df ) * 0.6
  training_indices = sample(seq_len(nrow(clean_df)), size= trainSize)
  trainSet = clean_df[ training_indices, ]
  testSet <- clean_df[-training_indices, ]
  testSetSim <- testSet
  finalModel <- lm( Data_Value ~  Age + Education + Gender + Income + Race + QuestionID + LocationAbbr, data = trainSet)
  testSet <- testSet %>% add_predictions(finalModel)
  dist <- rmse(finalModel, data = testSet)
  
  simplifiedModel <- lm(Data_Value ~ Gender + Race + QuestionID, data = trainSet )
  testSetSim <- testSetSim %>% add_predictions(simplifiedModel) 
  distSim <- rmse(simplifiedModel, data = testSetSim)
  


```
    	The general wide range model has Root-Mean-Squared-Error(RMSE) `r dist`, while the simplified model with only considering Gender, Race and QuestionID has RMSE as `r distSim`. There is only `r abs(dist - distSim)` different, which indicate we can use Gender, Race and QuestionID to represent the model with no significant sacrifice of the accuracy of the model generated. 
          
  4.  **summary of findings/recommendation**
  When we look at the residuals, which verifies that we've successfully removed the strong linear pattern.  We can now redo our plots using those residuals instead of Data_Value (our dependent variable). Now we see the relationships: 
  There are strong correlation between Data_Value and Gender, Race and Question;  and there are less correlation between Data_Value and Age, Location and Education. There is no relationships between Data_Value and Year and SampleSize. 
  The probably explanation on this may suggest obesity risk may higher among male, but less possible among female. Also, if you are Asian, then the chance to get Obesity is less. Of course, the way you address your questions about Obesity will lead you to different results. 
  

*References*
